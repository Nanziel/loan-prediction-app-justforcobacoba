# -*- coding: utf-8 -*-
"""LoanPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15VDMikojorzfrw7i_XQBDojg4s4dKpnH

# Upgrade sklearn to match with my local version (and make requirement.txt)
"""

!pip install --upgrade scikit-learn

import sklearn
print(sklearn.__version__)

import subprocess

def get_package_version(package_name):
    try:
        result = subprocess.run(['pip', 'show', package_name], capture_output=True, text=True, check=True)
        for line in result.stdout.splitlines():
            if line.startswith('Version:'):
                return line.split(' ')[1].strip()
    except subprocess.CalledProcessError:
        return "Not Found"
    return "Not Found"

pandas_version = get_package_version('pandas')
numpy_version = get_package_version('numpy')
sklearn_version = get_package_version('scikit-learn')

print(f"pandas=={pandas_version}")
print(f"numpy=={numpy_version}")
print(f"scikit-learn=={sklearn_version}")

requirements_content = f"""pandas==2.2.2
numpy==1.26.4
scikit-learn==1.8.0
"""
with open('requirements.txt', 'w') as f:
    f.write(requirements_content)

"""# Pemuatan dan Pengecekan"""

import pandas as pd

# Load the 'train.csv' file into a pandas DataFrame
train_df = pd.read_csv('/content/train.csv')

# Load the 'test.csv' file into a pandas DataFrame
test_df = pd.read_csv('/content/test.csv')

test_df = test_df.drop('Loan_ID', axis=1)
train_df = train_df.drop('Loan_ID', axis=1)

print("Train DataFrame head:")
display(train_df.head())
print("\nTest DataFrame head:")
display(test_df.head())

display(train_df.info())
display(test_df.info())

print("Null values in train_df:")
print(train_df.isnull().sum())

print("\nNull values in test_df:")
print(test_df.isnull().sum())

"""# Preprocessing"""

import numpy as np
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OrdinalEncoder
from sklearn.model_selection import GridSearchCV
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder
from sklearn.impute import KNNImputer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier

train_df['Dependents'] = train_df['Dependents'].replace('3+', 3)
test_df['Dependents'] = test_df['Dependents'].replace('3+', 3)

# Pisahkan fitur (X) dan target (y) dari train_df
X = train_df.drop('Loan_Status', axis=1)
y = train_df['Loan_Status'].map({'Y': 1, 'N': 0}) # Ubah Y/N jadi 1/0

# Setup Preprocessing
cat_cols = ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area']
num_cols = ['Dependents', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']

# Transformer untuk mengubah teks ke angka
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), cat_cols),
        ('num', 'passthrough', num_cols)
    ]
)

# Siapkan beberapa model
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000, solver='liblinear'),
    'Random Forest': RandomForestClassifier(random_state=42),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'SVM': SVC(),
    'KNN Classifier': KNeighborsClassifier()
}

# Pencarian model terbaik
results = []

for name, model in models.items():
    # Prepro -> Imputer -> Model
    pipe = Pipeline([
        ('prep', preprocessor),
        ('imputer', KNNImputer()),
        ('algo', model)
    ])

    # Tuning parameter 'n_neighbors' milik KNNImputer
    param_grid = {'imputer__n_neighbors': list(range(3, 13, 2))}

    # Jalankan GridSearchCV untuk mencari K terbaik KHUSUS untuk model ini
    grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')
    grid.fit(X, y)

    # Simpan hasil skor dan K terbaiknya
    results.append({
        'Model': name,
        'Best_K_Imputer': grid.best_params_['imputer__n_neighbors'],
        'Score': grid.best_score_
    })

# Tampilkan dalam bentuk tabel agar mudah dibandingkan
df_results = pd.DataFrame(results).sort_values(by='Score', ascending=False)
print(df_results)

"""# Modelling"""

# 1. Kita ambil 'Pemenang' dari hasil audisi tadi (Logistic Regression)
# Kita buat pipeline finalnya
final_pipe = Pipeline([
    ('prep', preprocessor),
    ('imputer', KNNImputer()),
    ('algo', LogisticRegression(max_iter=1000, solver='liblinear'))
])

# 2. Sekarang kita tuning SEMUANYA sekaligus (K imputer + Parameter Model)
# Hyperparameter yang lebih lengkap
param_grid = {
    # 1. Tuning Pengisian Data (Imputer)
    'imputer__n_neighbors': list(range(3, 13, 2)),

    # 2. Tuning Kekuatan Regulasi (C)
    # Mencoba jangkauan yang sangat luas dari 0.001 sampai 1000
    'algo__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],

    # 3. Tuning Jenis Penalty
    'algo__penalty': ['l1', 'l2'],

    # 4. Handling Imbalance Data
    # None: Menganggap jumlah Y dan N sama penting
    # 'balanced': Memberi bobot lebih pada data yang jumlahnya sedikit agar tidak terabaikan
    'algo__class_weight': [None, 'balanced'],

    # 5. Solver (Mesin Hitung)
    # liblinear bagus untuk dataset kecil, tapi kita pastikan di sini
    'algo__solver': ['liblinear']
}

grid_final = GridSearchCV(final_pipe, param_grid, cv=5, scoring='accuracy')
grid_final.fit(X, y)

# --- INI JAWABANNYA ---
# Objek 'model_siap_pakai' ini sudah mengandung:
# 1. Cara mengubah teks ke angka yang benar
# 2. Cara mengisi nilai null dengan K terbaik yang sudah ditemukan
# 3. Cara memprediksi dengan Logistic Regression yang sudah paling optimal
model_siap_pakai = grid_final.best_estimator_

# Sekarang kalau kamu mau prediksi data TEST yang masih banyak NULL-nya:
prediksi_test = model_siap_pakai.predict(test_df) # OTOMATIS BERSIH DAN TERISI!

print("Parameter terbaik ditemukan: ", grid_final.best_params_)

"""# Hasil"""

import pickle

# 1. Ambil model terbaik (yang sudah include Encoder + Imputer + LR)
model_siap_pakai = grid_final.best_estimator_

# 2. Simpan ke dalam file bernama 'best_loan_model.sav'
# 'wb' artinya Write Binary (menulis file dalam format biner)
filename = 'best_loan_model.sav'
pickle.dump(model_siap_pakai, open(filename, 'wb'))

print(f"Model berhasil disimpan dengan nama: {filename}")